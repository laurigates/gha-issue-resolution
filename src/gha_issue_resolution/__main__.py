# src/gha_issue_resolution/process_issues.py

import os
import json
from github import Github
from pathlib import Path
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from google.generativeai.types import GenerationConfig

# Setup GitHub client
g = Github(os.environ['GITHUB_TOKEN'])
repo = g.get_repo(os.environ['GITHUB_REPOSITORY'])

# Setup Gemini API
GEMINI_API_KEY = os.environ['GEMINI_API_KEY']
genai.configure(api_key=GEMINI_API_KEY)

# Set a large default max token limit
MAX_TOKENS = int(os.environ.get('MAX_TOKENS', '8192'))

# Specify the Gemini Flash model
MODEL_ID = 'gemini-1.5-flash-002'

# Set model parameters
generation_config = GenerationConfig(
    temperature=0.7,
    top_p=1.0,
    top_k=32,
    candidate_count=1,
    max_output_tokens=MAX_TOKENS,
)

# Set safety settings
safety_settings = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
}

def get_repo_structure():
    structure = ""
    for file in Path('.').rglob('*'):
        if file.is_file() and '.git' not in file.parts:
            structure += f"- {file}\n"
    return structure

def get_file_content(file_path, max_chars=100000):
    try:
        with open(file_path, 'r') as file:
            content = file.read(max_chars)
            if len(content) == max_chars:
                content += "\n... (file truncated due to size)"
            return content
    except Exception as e:
        return f"Error reading file: {str(e)}"

def query_gemini(prompt):
    model = genai.GenerativeModel(
        MODEL_ID,
        generation_config=generation_config,
        safety_settings=safety_settings,
    )
    response = model.generate_content([
        genai.types.ContentDict({
            'role': 'user',
            'parts': [
                "You are an AI assistant specialized in analyzing GitHub issues and suggesting solutions. "
                "Your task is to provide detailed, actionable advice for resolving the given issue.",
                prompt
            ]
        })
    ])
    print(f"\nUsage metadata:\n{response.prompt_feedback}")
    print(f"\nFinish reason:\n{response.candidates[0].finish_reason}")
    print(f"\nSafety ratings:\n{response.candidates[0].safety_ratings}")
    return response.text

def process_issue(issue):
    # Check if we've already commented on this issue
    for comment in issue.get_comments():
        if "AI-generated suggestion" in comment.body:
            print(f"Already commented on issue #{issue.number}. Skipping.")
            return

    repo_structure = get_repo_structure()
    initial_prompt = f"""
    Analyze this GitHub issue and suggest a solution based on the repository structure:
    
    Issue Title: {issue.title}
    Issue Body: {issue.body}
    
    Repository Structure:
    {repo_structure}
    
    Provide:
    1. A brief analysis of the issue.
    2. A list of files that are likely relevant to this issue (up to 5 files).
    3. An initial approach for solving this issue.
    """
    
    initial_response = query_gemini(initial_prompt)
    
    # Extract file paths from the initial response
    file_paths = [line.split()[-1] for line in initial_response.split('\n') if line.startswith('-') and '.' in line]
    
    # Get content of identified files
    file_contents = ""
    for file_path in file_paths[:5]:  # Limit to 5 files
        if Path(file_path).is_file():
            file_contents += f"\nContent of {file_path}:\n```\n{get_file_content(file_path)}\n```\n"

    # Second prompt with file contents
    detailed_prompt = f"""
    Based on the initial analysis and the content of the relevant files, provide a detailed solution:

    Issue Title: {issue.title}
    Issue Body: {issue.body}

    Initial Analysis and Suggestion:
    {initial_response}

    Relevant File Contents:
    {file_contents}

    Please provide:
    1. A detailed solution to the issue, including specific code changes if applicable.
    2. An explanation of why these changes would resolve the issue.
    3. Any potential side effects or considerations to keep in mind when implementing this solution.
    """

    detailed_solution = query_gemini(detailed_prompt)
    
    comment_body = f"""
    ## AI-generated suggestion

    Here's a potential solution to this issue, generated by an AI assistant:

    {detailed_solution}

    Please review this suggestion and let me know if you need any clarification or have any questions.
    This is an AI-generated response and may require human validation and testing before implementation.
    """
    
    issue.create_comment(comment_body)
    print(f"Commented on issue #{issue.number}")

def main():
    print(f"Starting Issue Resolution with Gemini Flash (Model: {MODEL_ID})")
    
    # Check if we're running in response to an issue event
    if 'GITHUB_EVENT_NAME' in os.environ and os.environ['GITHUB_EVENT_NAME'] == 'issues':
        event_path = os.environ['GITHUB_EVENT_PATH']
        print(f"Processing GitHub event from {event_path}")
        with open(event_path, 'r') as f:
            event_data = json.load(f)
        
        action = event_data['action']
        if action in ['opened', 'reopened']:
            issue_number = event_data['issue']['number']
            print(f"Processing issue #{issue_number}")
            issue = repo.get_issue(issue_number)
            process_issue(issue)
        else:
            print(f"Ignoring issue event with action: {action}")
    else:
        print("No specific issue event detected. Processing all open issues.")
        open_issues = repo.get_issues(state='open')
        for issue in open_issues:
            process_issue(issue)

    print("Finished Issue Resolution with Gemini Flash")

if __name__ == "__main__":
    main()
